I"L<p>Auspice by Goorm, Manage by DAVIAN @ KAIST</p>

<h2 id="lecture-logistic-regression">Lecture: Logistic Regression</h2>

<p>2022-01-26</p>

<p>지금까지 주어진 데이터와 가장 잘 맞는 직선을 찾는 <u>Linear Regression</u>을 진행했었다.</p>

<p>이번에는 예측 값이 연속적인 값을 갖지 않는 <strong>Logistic Regression</strong>에 대해서 알아볼 것이다.</p>

<h2 id="classification">Classification</h2>

<p><img src="https://user-images.githubusercontent.com/67947808/151110845-ed47db3c-044a-476a-bbd1-a5b7d95ed32c.png" alt="스크린샷 2022-01-26 오후 2 52 41" style="zoom:67%;" /></p>

<p><img src="https://user-images.githubusercontent.com/67947808/151110968-53e6a463-d30c-4d1e-83a0-2567e3715235.png" alt="스크린샷 2022-01-26 오후 2 54 01" style="zoom: 67%;" /></p>

<h2 id="logistic-function">Logistic function</h2>

<p>Logistic regression을 진행하기 위해서는 출력 값을 0과 1의 값으로 맞춰주어야 한다.</p>

<p>이를 위해서 <strong>logistic function</strong> 을 사용했고, Logistic function은 아래와 같다.</p>

<p>$\sigma(z) = \frac{1}{1 + e^{-z}}$</p>

<p><img src="https://user-images.githubusercontent.com/67947808/151111302-e49140c7-b8ab-4fac-8cc1-4b3a4c4bafcf.png" alt="image" /></p>

<p>Logistic regression을 진행할 때 입력 데이터를 $x$, 실제 class 값을 $y$, 예측된 출력 값을 $\hat{y}$라고 하면 $x$는 두가지 변환을 거쳐서 $\hat{y}$가 된다.</p>

<p>$z = wx + b$
$\hat{y} = \sigma(z)$</p>

<p>위에 있는 식의 목표는 $\hat{y}$가 실제 $y$와 가장 가깝게 되도록 하는 $w$와 $b$를 찾는 것 이다.</p>

<h2 id="logistic-loss-function">Logistic loss function</h2>

<p>$\sigma(z) = \frac{1}{1 + e^{-z}}$</p>

<p>$\sigma’(z) = \sigma(z) ( 1 - \sigma(z))$</p>

<p>$\frac{\partial{L}}{\partial{\sigma(z)}} = \frac{(y-\sigma(z))}{\sigma(z)(1-\sigma(z))}$</p>

<p>위와 같은 과정을 통해 구한 cost function $L$은 
$L = -y \log(a) + (y-1)\log(1-a)$이 된다.</p>

<p>만약 $y=1$이라면 $L = -\log(a)$만 남게 되며, 그래프로 표현하면 다음과 같다.<br />
실제 class가 1일때 예측 값이 0에 가까워지면 cost function 값이 커지고, 1에 가까워지면 cost function 값이 작아지는 것을 알 수 있다.</p>

<p><img src="https://user-images.githubusercontent.com/67947808/151111896-942a871a-1abd-4a07-a3e2-7bf81a677637.png" alt="image" /></p>

<p>이제 $y=0$이라면 $L = \log(1-a)$ 만 남게 되며, 그래프로 표현하면 다음과 같다.<br />
예측 값이 실제 값이랑 가까워지면 cost function 값이 작아지고 멀어지면 커지게 됨을 알 수 있다.</p>

<p><img src="https://user-images.githubusercontent.com/67947808/151112076-8f7cfbef-4506-40fc-ae3b-1967e4fe8f71.png" alt="image" /></p>

<h2 id="logistic-regression-example">Logistic Regression example</h2>

<p><img src="https://user-images.githubusercontent.com/67947808/151112156-4497c2ab-2a8d-4345-91fd-aebb32f6c82a.png" alt="image" /></p>

<p>빨간색 곡선이 Logistic Regression의 모델이다.<br />
기준값을 정한 후, 그것보다 크면 1, 작으면 0으로 분류를 진행하게 된다.<br />
아래 사진은 기준값을 0.5로 설정한 예시이다.</p>

<p><img src="https://user-images.githubusercontent.com/67947808/151112386-0d305db3-0515-477d-a554-776a5db3dca7.png" alt="image" /></p>

:ET