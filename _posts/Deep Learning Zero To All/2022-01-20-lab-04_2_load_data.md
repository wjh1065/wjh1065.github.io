---
title: "Deep Learning Zero To All - Pytorch (1일 차) - 5"  
categories:
 - Deep Learning Zero To All
tags:
 - study
 - python
 - pytorch
use_math: true
---

# Lab 4-2: Load Data

Author: Seungjae Lee (이승재)

<div class="alert alert-warning">
    We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as <code>nn.Module</code> or <code>nn.Linear</code> are used.
</div>

## Slicing 1D Array


```python
nums = [0, 1, 2, 3, 4]
```


```python
print(nums)
```

    [0, 1, 2, 3, 4]


index 2에서 4 전까지 가져와라. (앞 포함, 뒤 비포함)


```python
print(nums[2:4])
```

    [2, 3]


index 2부터 다 가져와라.


```python
print(nums[2:])
```

    [2, 3, 4]


index 2 전까지 가져와라. (역시 뒤는 비포함)


```python
print(nums[:2])
```

    [0, 1]


전부 가져와라


```python
print(nums[:])
```

    [0, 1, 2, 3, 4]


마지막 index 전까지 가져와라. (뒤는 비포함!)


```python
print(nums[:-1])
```

    [0, 1, 2, 3]


assign 도 가능!


```python
nums[2:4] = [8, 9]
```


```python
print(nums)
```

    [0, 1, 8, 9, 4]


## Slicing 2D Array


```python
import numpy as np
```


```python
b = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```


```python
print(b)
```

    [[ 1  2  3  4]
     [ 5  6  7  8]
     [ 9 10 11 12]]



```python
b[:, 1]
```




    array([ 2,  6, 10])




```python
b[-1]
```




    array([ 9, 10, 11, 12])




```python
b[-1, :]
```




    array([ 9, 10, 11, 12])




```python
b[-1, ...]
```




    array([ 9, 10, 11, 12])




```python
b[0:2, :]
```




    array([[1, 2, 3, 4],
           [5, 6, 7, 8]])



## Loading Data from `.csv` file


```python
import numpy as np
```


```python
xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)
xy
```




    array([[ 73.,  80.,  75., 152.],
           [ 93.,  88.,  93., 185.],
           [ 89.,  91.,  90., 180.],
           [ 96.,  98., 100., 196.],
           [ 73.,  66.,  70., 142.],
           [ 53.,  46.,  55., 101.],
           [ 69.,  74.,  77., 149.],
           [ 47.,  56.,  60., 115.],
           [ 87.,  79.,  90., 175.],
           [ 79.,  70.,  88., 164.],
           [ 69.,  70.,  73., 141.],
           [ 70.,  65.,  74., 141.],
           [ 93.,  95.,  91., 184.],
           [ 79.,  80.,  73., 152.],
           [ 70.,  73.,  78., 148.],
           [ 93.,  89.,  96., 192.],
           [ 78.,  75.,  68., 147.],
           [ 81.,  90.,  93., 183.],
           [ 88.,  92.,  86., 177.],
           [ 78.,  83.,  77., 159.],
           [ 82.,  86.,  90., 177.],
           [ 86.,  82.,  89., 175.],
           [ 78.,  83.,  85., 175.],
           [ 76.,  83.,  71., 149.],
           [ 96.,  93.,  95., 192.]], dtype=float32)




```python
x_data = xy[:, 0:-1]
y_data = xy[:, [-1]]
```


```python
print(x_data.shape) # x_data shape
print(len(x_data))  # x_data 길이
print(x_data[:5])   # 첫 다섯 개
```

    (25, 3)
    25
    [[ 73.  80.  75.]
     [ 93.  88.  93.]
     [ 89.  91.  90.]
     [ 96.  98. 100.]
     [ 73.  66.  70.]]



```python
print(y_data.shape) # y_data shape
print(len(y_data))  # y_data 길이
print(y_data[:5])   # 첫 다섯 개
```

    (25, 1)
    25
    [[152.]
     [185.]
     [180.]
     [196.]
     [142.]]


## Imports


```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
```


```python
# For reproducibility
torch.manual_seed(1)
```




    <torch._C.Generator at 0x403df41ef0>



## Low-level Implementation


```python
# 데이터
x_train = torch.FloatTensor(x_data)
y_train = torch.FloatTensor(y_data)
# 모델 초기화
W = torch.zeros((3, 1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
# optimizer 설정
optimizer = optim.SGD([W, b], lr=1e-5)

nb_epochs = 20
for epoch in range(nb_epochs + 1):
    
    # H(x) 계산
    hypothesis = x_train.matmul(W) + b # or .mm or @

    # cost 계산
    cost = torch.mean((hypothesis - y_train) ** 2)

    # cost로 H(x) 개선
    optimizer.zero_grad()
    cost.backward()
    optimizer.step()

    # 100번마다 로그 출력
    print('Epoch {:4d}/{} Cost: {:.6f}'.format(
        epoch, nb_epochs, cost.item()
    ))
```

    Epoch    0/20 Cost: 26811.960938
    Epoch    1/20 Cost: 9920.529297
    Epoch    2/20 Cost: 3675.299072
    Epoch    3/20 Cost: 1366.261108
    Epoch    4/20 Cost: 512.542236
    Epoch    5/20 Cost: 196.896484
    Epoch    6/20 Cost: 80.190910
    Epoch    7/20 Cost: 37.038647
    Epoch    8/20 Cost: 21.081354
    Epoch    9/20 Cost: 15.178741
    Epoch   10/20 Cost: 12.993667
    Epoch   11/20 Cost: 12.183028
    Epoch   12/20 Cost: 11.880545
    Epoch   13/20 Cost: 11.765955
    Epoch   14/20 Cost: 11.720857
    Epoch   15/20 Cost: 11.701424
    Epoch   16/20 Cost: 11.691505
    Epoch   17/20 Cost: 11.685121
    Epoch   18/20 Cost: 11.680006
    Epoch   19/20 Cost: 11.675381
    Epoch   20/20 Cost: 11.670943


## High-level Implementation with `nn.Module`


```python
class MultivariateLinearRegressionModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(3, 1)

    def forward(self, x):
        return self.linear(x)
```


```python
# 데이터
x_train = torch.FloatTensor(x_data)
y_train = torch.FloatTensor(y_data)
# 모델 초기화
model = MultivariateLinearRegressionModel()
# optimizer 설정
optimizer = optim.SGD(model.parameters(), lr=1e-5)

nb_epochs = 20
for epoch in range(nb_epochs+1):
    
    # H(x) 계산
    prediction = model(x_train)
    
    # cost 계산
    cost = F.mse_loss(prediction, y_train)
    
    # cost로 H(x) 개선
    optimizer.zero_grad()
    cost.backward()
    optimizer.step()
    
    # 20번마다 로그 출력
    print('Epoch {:4d}/{} Cost: {:.6f}'.format(
        epoch, nb_epochs, cost.item()
    ))
```

    Epoch    0/20 Cost: 2560.803955
    Epoch    1/20 Cost: 955.054138
    Epoch    2/20 Cost: 361.360779
    Epoch    3/20 Cost: 141.852600
    Epoch    4/20 Cost: 60.690659
    Epoch    5/20 Cost: 30.679520
    Epoch    6/20 Cost: 19.580132
    Epoch    7/20 Cost: 15.472973
    Epoch    8/20 Cost: 13.950972
    Epoch    9/20 Cost: 13.384814
    Epoch   10/20 Cost: 13.172079
    Epoch   11/20 Cost: 13.089987
    Epoch   12/20 Cost: 13.056224
    Epoch   13/20 Cost: 13.040330
    Epoch   14/20 Cost: 13.031028
    Epoch   15/20 Cost: 13.024179
    Epoch   16/20 Cost: 13.018215
    Epoch   17/20 Cost: 13.012632
    Epoch   18/20 Cost: 13.007132
    Epoch   19/20 Cost: 13.001721
    Epoch   20/20 Cost: 12.996302


## Dataset and DataLoader

<div class="alert alert-warning">
    pandas 기초지식이 필요할 것 같다
</div>


```python
from torch.utils.data import Dataset

class CustomDataset(Dataset):
    def __init__(self):
        self.x_data = [[73,80,75],
                      [93,88,93],
                      [96,98,100],
                      [73,66,70]]
        self.y_data = [[152],[185],[180],[196],[142]]
        
    def __len__(self):
        return len(self.x_data)
    
    def __getitem__(self,idx):
        x = torch.FloatTensor(self.x_data[idx])
        y = torch.FloatTensor(self.y_data[idx])
        
        return x,y
    
dataset = CustomDataset()

from torch.utils.data import DataLoader

dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
```


```python
nb_epochs = 20
for epoch in range(nb_epochs+1):
    for batch_idx, samples in enumerate(dataloader):
        x_train, y_train = samples
        
        # H(x) 계산
        prediction = model(x_train)
    
        # cost 계산
        cost = F.mse_loss(prediction, y_train)
    
        # cost로 H(x) 개선
        optimizer.zero_grad()
        cost.backward()
        optimizer.step()
    
        # 20번마다 로그 출력
        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(
            epoch, nb_epochs, batch_idx+1,len(dataloader),cost.item()
        ))
```

    Epoch    0/20 Batch 1/2 Cost: 1213.129395
    Epoch    0/20 Batch 2/2 Cost: 612.548767
    Epoch    1/20 Batch 1/2 Cost: 175.380692
    Epoch    1/20 Batch 2/2 Cost: 1560.875854
    Epoch    2/20 Batch 1/2 Cost: 1128.105835
    Epoch    2/20 Batch 2/2 Cost: 700.591919
    Epoch    3/20 Batch 1/2 Cost: 1312.350464
    Epoch    3/20 Batch 2/2 Cost: 523.178833
    Epoch    4/20 Batch 1/2 Cost: 158.718887
    Epoch    4/20 Batch 2/2 Cost: 1600.766357
    Epoch    5/20 Batch 1/2 Cost: 47.131451
    Epoch    5/20 Batch 2/2 Cost: 1473.253296
    Epoch    6/20 Batch 1/2 Cost: 1142.540039
    Epoch    6/20 Batch 2/2 Cost: 601.339172
    Epoch    7/20 Batch 1/2 Cost: 1269.532349
    Epoch    7/20 Batch 2/2 Cost: 556.251831
    Epoch    8/20 Batch 1/2 Cost: 1.875856
    Epoch    8/20 Batch 2/2 Cost: 1535.726562
    Epoch    9/20 Batch 1/2 Cost: 292.746979
    Epoch    9/20 Batch 2/2 Cost: 1490.381348
    Epoch   10/20 Batch 1/2 Cost: 1089.752197
    Epoch   10/20 Batch 2/2 Cost: 739.506897
    Epoch   11/20 Batch 1/2 Cost: 1490.575195
    Epoch   11/20 Batch 2/2 Cost: 45.611748
    Epoch   12/20 Batch 1/2 Cost: 1255.198853
    Epoch   12/20 Batch 2/2 Cost: 499.337097
    Epoch   13/20 Batch 1/2 Cost: 191.701660
    Epoch   13/20 Batch 2/2 Cost: 1562.451172
    Epoch   14/20 Batch 1/2 Cost: 53.253944
    Epoch   14/20 Batch 2/2 Cost: 1462.039917
    Epoch   15/20 Batch 1/2 Cost: 343.420441
    Epoch   15/20 Batch 2/2 Cost: 1401.213745
    Epoch   16/20 Batch 1/2 Cost: 434.845764
    Epoch   16/20 Batch 2/2 Cost: 1407.953125
    Epoch   17/20 Batch 1/2 Cost: 1048.746094
    Epoch   17/20 Batch 2/2 Cost: 785.950928
    Epoch   18/20 Batch 1/2 Cost: 213.489975
    Epoch   18/20 Batch 2/2 Cost: 1540.415405
    Epoch   19/20 Batch 1/2 Cost: 57.037704
    Epoch   19/20 Batch 2/2 Cost: 1455.791016
    Epoch   20/20 Batch 1/2 Cost: 1414.848022
    Epoch   20/20 Batch 2/2 Cost: 90.759705


너무 데이터가 크면 `x_data`, `y_data` 를 전부 다 가져오지 말고, 필요한 배치만 가져올 수 밖에 없다.

[PyTorch Data Loading and Processing tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#iterating-through-the-dataset)
